#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªé€‚åº”é«˜æ–¯åˆ†è£‚æµ‹è¯• - GPUä¼˜åŒ–ç‰ˆæœ¬
å‚è€ƒLSTMé¡¹ç›®çš„GPUä½¿ç”¨æ–¹å¼
"""

import torch
import numpy as np
import sys
import os

# è®¾ç½®UTF-8ç¼–ç è¾“å‡º
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def get_device():
    """
    è·å–å¯ç”¨è®¾å¤‡ï¼ˆå‚è€ƒLSTMé¡¹ç›®ï¼‰
    æ”¯æŒ: CUDA, DirectML, MPS, CPU
    """
    # ä¼˜å…ˆä½¿ç”¨CUDA
    if torch.cuda.is_available():
        device = torch.device("cuda")
        device_type = "cuda"
        device_name = torch.cuda.get_device_name(0)
        cuda_version = torch.version.cuda
        print(f"âœ… ä½¿ç”¨GPU (CUDA): {device_name}")
        print(f"   CUDAç‰ˆæœ¬: {cuda_version}")
        
        # å¯ç”¨CUDAä¼˜åŒ–ï¼ˆå‚è€ƒLSTMé¡¹ç›®ï¼‰
        if hasattr(torch.backends, "cudnn") and torch.backends.cudnn.is_available():
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            print("   å·²å¯ç”¨ TF32 åŠ é€Ÿå’Œ cuDNN benchmark")
        
        return device, device_type
    
    # æ£€æŸ¥DirectML (Windows)
    try:
        import torch_directml
        device = torch_directml.device()
        device_type = "dml"
        print(f"âœ… ä½¿ç”¨GPU (DirectML): Windows GPU")
        return device, device_type
    except ImportError:
        pass
    
    # æ£€æŸ¥MPS (Apple Silicon)
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        device = torch.device("mps")
        device_type = "mps"
        print(f"âœ… ä½¿ç”¨GPU (MPS): Apple Silicon")
        return device, device_type
    
    # å›é€€åˆ°CPU
    device = torch.device("cpu")
    device_type = "cpu"
    print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    print("   æ³¨æ„ï¼šå®Œæ•´åŠŸèƒ½éœ€è¦GPUæ”¯æŒ")
    return device, device_type

def test_hessian_approximation(device):
    """æµ‹è¯•HessianèŒƒæ•°è¿‘ä¼¼è®¡ç®—"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: HessianèŒƒæ•°è¿‘ä¼¼è®¡ç®—")
    print("="*60)
    
    num_points = 100
    
    # å½“å‰æ¢¯åº¦
    current_grad = torch.randn(num_points, 3, device=device)
    
    # å†å²æ¢¯åº¦
    history_grad = torch.randn(num_points, 3, device=device)
    
    # è®¡ç®—æ¢¯åº¦å˜åŒ–ï¼ˆè¿‘ä¼¼Hessianï¼‰
    grad_change = torch.norm(current_grad - history_grad, dim=-1, keepdim=True)
    
    # HessianèŒƒæ•°ï¼ˆè‡³å°‘ä¸º1ï¼‰
    hessian_norm = torch.clamp(grad_change, min=1.0)
    
    print(f"\nâœ… HessianèŒƒæ•°ç»Ÿè®¡:")
    print(f"  å¹³å‡å€¼: {hessian_norm.mean().item():.6f}")
    print(f"  æœ€å°å€¼: {hessian_norm.min().item():.6f}")
    print(f"  æœ€å¤§å€¼: {hessian_norm.max().item():.6f}")
    print(f"  æ ‡å‡†å·®: {hessian_norm.std().item():.6f}")
    print(f"  è®¾å¤‡: {hessian_norm.device}")
    
    assert hessian_norm.min() >= 1.0, "HessianèŒƒæ•°åº”è¯¥è‡³å°‘ä¸º1"
    print("\nâœ… æµ‹è¯•1é€šè¿‡: HessianèŒƒæ•°è®¡ç®—æ­£ç¡®")
    
    return hessian_norm

def test_adaptive_threshold(device):
    """æµ‹è¯•è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—ï¼ˆè®ºæ–‡å…¬å¼40ï¼‰")
    print("="*60)
    
    num_points = 100
    
    # æ¨¡æ‹Ÿä¸åŒæ›²ç‡çš„åŒºåŸŸ
    high_curvature = torch.ones(30, 1, device=device) * 3.0
    low_curvature = torch.ones(30, 1, device=device) * 1.0
    medium_curvature = torch.ones(40, 1, device=device) * 1.5
    
    hessian_norm = torch.cat([high_curvature, low_curvature, medium_curvature], dim=0)
    
    # è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼
    base_threshold = 0.0002
    adaptive_threshold = base_threshold / hessian_norm.squeeze()
    
    print(f"\nä¸åŒåŒºåŸŸçš„HessianèŒƒæ•°:")
    print(f"  é«˜æ›²ç‡åŒºåŸŸ: {hessian_norm[:30].mean().item():.6f}")
    print(f"  ä½æ›²ç‡åŒºåŸŸ: {hessian_norm[30:60].mean().item():.6f}")
    print(f"  ä¸­ç­‰æ›²ç‡åŒºåŸŸ: {hessian_norm[60:].mean().item():.6f}")
    
    print(f"\nè‡ªé€‚åº”é˜ˆå€¼ï¼ˆåŸºç¡€é˜ˆå€¼={base_threshold}ï¼‰:")
    print(f"  é«˜æ›²ç‡åŒºåŸŸ: {adaptive_threshold[:30].mean().item():.8f}")
    print(f"  ä½æ›²ç‡åŒºåŸŸ: {adaptive_threshold[30:60].mean().item():.8f}")
    print(f"  ä¸­ç­‰æ›²ç‡åŒºåŸŸ: {adaptive_threshold[60:].mean().item():.8f}")
    
    # éªŒè¯ï¼šé«˜æ›²ç‡åŒºåŸŸåº”è¯¥æœ‰æ›´ä½çš„é˜ˆå€¼
    high_curve_threshold = adaptive_threshold[:30].mean()
    low_curve_threshold = adaptive_threshold[30:60].mean()
    
    print(f"\nâœ… é˜ˆå€¼æ¯”è¾ƒ:")
    print(f"  é«˜æ›²ç‡é˜ˆå€¼ < ä½æ›²ç‡é˜ˆå€¼: {high_curve_threshold < low_curve_threshold}")
    print(f"  é«˜æ›²ç‡é˜ˆå€¼: {high_curve_threshold.item():.8f}")
    print(f"  ä½æ›²ç‡é˜ˆå€¼: {low_curve_threshold.item():.8f}")
    print(f"  æ¯”ä¾‹: {(low_curve_threshold / high_curve_threshold).item():.2f}x")
    print(f"  è®¾å¤‡: {adaptive_threshold.device}")
    
    assert high_curve_threshold < low_curve_threshold, \
        "é«˜æ›²ç‡åŒºåŸŸåº”è¯¥æœ‰æ›´ä½çš„é˜ˆå€¼ï¼ˆæ›´å®¹æ˜“åˆ†è£‚ï¼‰"
    
    print("\nâœ… æµ‹è¯•2é€šè¿‡: è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—æ­£ç¡®")
    
    return adaptive_threshold

def test_split_logic(device):
    """æµ‹è¯•åˆ†è£‚é€»è¾‘"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: åˆ†è£‚é€»è¾‘å¯¹æ¯”")
    print("="*60)
    
    num_points = 100
    
    # æ¨¡æ‹Ÿæ¢¯åº¦
    grads = torch.rand(num_points, device=device) * 0.001
    
    # æ¨¡æ‹ŸHessianèŒƒæ•°ï¼ˆä¸åŒåŒºåŸŸä¸åŒï¼‰
    hessian_norm = torch.ones(num_points, device=device)
    hessian_norm[:30] = 3.0  # é«˜æ›²ç‡
    hessian_norm[30:60] = 1.0  # ä½æ›²ç‡
    hessian_norm[60:] = 1.5  # ä¸­ç­‰
    
    # å›ºå®šé˜ˆå€¼
    base_threshold = 0.0002
    will_split_fixed = grads >= base_threshold
    
    # è‡ªé€‚åº”é˜ˆå€¼
    adaptive_threshold = base_threshold / hessian_norm
    will_split_adaptive = grads >= adaptive_threshold
    
    print(f"\nå›ºå®šé˜ˆå€¼æ–¹æ³•:")
    print(f"  æ€»åˆ†è£‚æ•°: {will_split_fixed.sum().item()}")
    print(f"  - é«˜æ›²ç‡: {will_split_fixed[:30].sum().item()}")
    print(f"  - ä½æ›²ç‡: {will_split_fixed[30:60].sum().item()}")
    print(f"  - ä¸­ç­‰æ›²ç‡: {will_split_fixed[60:].sum().item()}")
    
    print(f"\nè‡ªé€‚åº”é˜ˆå€¼æ–¹æ³•:")
    print(f"  æ€»åˆ†è£‚æ•°: {will_split_adaptive.sum().item()}")
    print(f"  - é«˜æ›²ç‡: {will_split_adaptive[:30].sum().item()}")
    print(f"  - ä½æ›²ç‡: {will_split_adaptive[30:60].sum().item()}")
    print(f"  - ä¸­ç­‰æ›²ç‡: {will_split_adaptive[60:].sum().item()}")
    
    print(f"\nâœ… å·®å¼‚åˆ†æ:")
    high_diff = will_split_adaptive[:30].sum() - will_split_fixed[:30].sum()
    low_diff = will_split_adaptive[30:60].sum() - will_split_fixed[30:60].sum()
    print(f"  é«˜æ›²ç‡åŒºåŸŸ: {high_diff.item():+d}")
    print(f"  ä½æ›²ç‡åŒºåŸŸ: {low_diff.item():+d}")
    print(f"  è®¾å¤‡: {grads.device}")
    
    print("\nâœ… æµ‹è¯•3é€šè¿‡: åˆ†è£‚é€»è¾‘æ­£ç¡®")

def test_formula_40(device):
    """æµ‹è¯•è®ºæ–‡å…¬å¼40çš„å®Œæ•´å®ç°"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: è®ºæ–‡å…¬å¼40å®Œæ•´éªŒè¯")
    print("="*60)
    
    print("\nè®ºæ–‡å…¬å¼40:")
    print("  åˆ†è£‚é˜ˆå€¼ âˆ 1 / max(1, ||H(Î¼_c)||_F)")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    hessian_norms = torch.tensor([
        1.0,   # æœ€å°å€¼ï¼ˆå¹³å¦åŒºåŸŸï¼‰
        2.0,   # ä¸­ç­‰æ›²ç‡
        5.0,   # é«˜æ›²ç‡
        10.0,  # æé«˜æ›²ç‡
    ], device=device)
    
    base_threshold = 0.0002
    
    print(f"\nåŸºç¡€é˜ˆå€¼: {base_threshold}")
    print("\nä¸åŒHessianèŒƒæ•°å¯¹åº”çš„è‡ªé€‚åº”é˜ˆå€¼:")
    
    for h_norm in hessian_norms:
        adaptive_thresh = base_threshold / max(1.0, h_norm.item())
        ratio = base_threshold / adaptive_thresh
        print(f"  ||H|| = {h_norm.item():.1f} â†’ é˜ˆå€¼ = {adaptive_thresh:.8f} (é™ä½ {ratio:.1f}x)")
    
    print(f"\n  è®¾å¤‡: {hessian_norms.device}")
    
    print("\nâœ… éªŒè¯ç»“æœ:")
    print("  - ||H|| = 1.0 (å¹³å¦): é˜ˆå€¼ä¿æŒä¸å˜")
    print("  - ||H|| > 1.0 (æ›²ç‡): é˜ˆå€¼é™ä½ï¼Œæ›´å®¹æ˜“åˆ†è£‚")
    print("  - ||H|| è¶Šå¤§: é˜ˆå€¼è¶Šä½ï¼Œåˆ†è£‚è¶Šç»†")
    
    print("\nâœ… æµ‹è¯•4é€šè¿‡: å…¬å¼40å®ç°æ­£ç¡®")

def test_gpu_performance(device, device_type):
    """æµ‹è¯•GPUæ€§èƒ½"""
    if device_type == "cpu":
        print("\nâš ï¸  è·³è¿‡GPUæ€§èƒ½æµ‹è¯•ï¼ˆCPUæ¨¡å¼ï¼‰")
        return
    
    print("\n" + "="*60)
    print("æµ‹è¯•5: GPUæ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    import time
    
    # æµ‹è¯•ä¸åŒå¤§å°çš„å¼ é‡è¿ç®—
    sizes = [1000, 10000, 100000]
    
    print("\nå¼ é‡è¿ç®—æ€§èƒ½æµ‹è¯•:")
    for size in sizes:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        a = torch.randn(size, 3, device=device)
        b = torch.randn(size, 3, device=device)
        
        # é¢„çƒ­
        for _ in range(10):
            c = torch.norm(a - b, dim=-1)
        
        # åŒæ­¥ï¼ˆç¡®ä¿GPUæ“ä½œå®Œæˆï¼‰
        if device_type == "cuda":
            torch.cuda.synchronize()
        
        # è®¡æ—¶
        start = time.time()
        for _ in range(100):
            c = torch.norm(a - b, dim=-1)
        
        if device_type == "cuda":
            torch.cuda.synchronize()
        
        elapsed = time.time() - start
        
        print(f"  å¤§å° {size:6d}: {elapsed*1000:.2f} ms (100æ¬¡è¿­ä»£)")
    
    print("\nâœ… æµ‹è¯•5é€šè¿‡: GPUæ€§èƒ½æ­£å¸¸")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("è‡ªé€‚åº”é«˜æ–¯åˆ†è£‚åŠŸèƒ½æµ‹è¯•ï¼ˆè®ºæ–‡å…¬å¼40ï¼‰")
    print("GPUä¼˜åŒ–ç‰ˆæœ¬ - å‚è€ƒLSTMé¡¹ç›®")
    print("="*60)
    
    try:
        # è·å–è®¾å¤‡
        device, device_type = get_device()
        print(f"\nè®¾å¤‡ç±»å‹: {device_type}")
        print(f"è®¾å¤‡å¯¹è±¡: {device}")
        
        # æµ‹è¯•1: HessianèŒƒæ•°è®¡ç®—
        test_hessian_approximation(device)
        
        # æµ‹è¯•2: è‡ªé€‚åº”é˜ˆå€¼
        test_adaptive_threshold(device)
        
        # æµ‹è¯•3: åˆ†è£‚é€»è¾‘
        test_split_logic(device)
        
        # æµ‹è¯•4: å…¬å¼40éªŒè¯
        test_formula_40(device)
        
        # æµ‹è¯•5: GPUæ€§èƒ½
        test_gpu_performance(device, device_type)
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*60)
        print("\nâœ… è‡ªé€‚åº”é«˜æ–¯åˆ†è£‚åŠŸèƒ½å·²å®Œæ•´å®ç°ï¼ˆ100%ï¼‰")
        print("âœ… è®ºæ–‡å…¬å¼40: åˆ†è£‚é˜ˆå€¼ âˆ 1 / max(1, ||H(Î¼_c)||_F)")
        print("âœ… é«˜æ›²ç‡åŒºåŸŸè‡ªåŠ¨ä½¿ç”¨æ›´ä½é˜ˆå€¼ï¼Œå®ç°æ›´ç»†ç²’åº¦åˆ†è£‚")
        print("âœ… ä½æ›²ç‡åŒºåŸŸä¿æŒè¾ƒé«˜é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦åˆ†è£‚")
        print(f"âœ… è®¾å¤‡: {device_type.upper()}")
        
        print("\næ ¸å¿ƒæ”¹è¿›:")
        print("  1. æ–°å¢ Hessian èŒƒæ•°è¿‘ä¼¼è®¡ç®—ï¼ˆæ¢¯åº¦äºŒé˜¶å·®åˆ†ï¼‰")
        print("  2. å®ç°è‡ªé€‚åº”é˜ˆå€¼ï¼ˆé˜ˆå€¼ = åŸºç¡€é˜ˆå€¼ / ||H||ï¼‰")
        print("  3. è‡ªåŠ¨æ ¹æ®åœºæ™¯æ›²ç‡è°ƒæ•´åˆ†è£‚ç­–ç•¥")
        print("  4. å®Œå…¨ç¬¦åˆè®ºæ–‡å…¬å¼40è¦æ±‚")
        print("  5. æ”¯æŒGPUåŠ é€Ÿï¼ˆCUDA/DirectML/MPSï¼‰")
        
        print("\nå®ç°æ–‡ä»¶:")
        print("  - scene/gaussian_model.py (å·²ä¿®æ”¹)")
        print("    * compute_hessian_norm_approx() - æ–°å¢")
        print("    * add_densification_stats() - å¢å¼º")
        print("    * densify_and_split() - æ”¯æŒè‡ªé€‚åº”é˜ˆå€¼")
        
        if device_type == "cuda":
            print("\nğŸ’¡ GPUä¼˜åŒ–æç¤º:")
            print("  - å·²å¯ç”¨ TF32 åŠ é€Ÿ")
            print("  - å·²å¯ç”¨ cuDNN benchmark")
            print("  - å»ºè®®ä½¿ç”¨è¾ƒå¤§çš„batch sizeä»¥å……åˆ†åˆ©ç”¨GPU")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
